name: Deploy MkDocs to GitHub Pages
on:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - run: pip install --upgrade pip
      - run: pip install mkdocs mkdocs-material mkdocs-roamlinks-plugin mkdocs-glightbox mkdocs-minify-plugin
      - run: pip install mkdocs mkdocs-material mkdocs-roamlinks-plugin mkdocs-glightbox mkdocs-minify-plugin mkdocs-rss-plugin mkdocs-sitemap-plugin
      - name: SEO normalize (front-matter + H1)
        run: |
          python - <<'PY'
          import re, pathlib
          from pathlib import Path

          def strip_md(t):
              t = re.sub(r'```.*?```', '', t, flags=re.S)
              t = re.sub(r'`[^`]*`', '', t)
              t = re.sub(r'!\[[^\]]*\]\([^)]+\)', '', t)
              t = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', t)
              t = re.sub(r'<[^>]+>', '', t)
              t = re.sub(r'\s+', ' ', t).strip()
              return t

          root = Path('docs')
          for p in root.rglob('*.md'):
              sp = str(p).replace('\\','/')
              if '/assets/' in sp: 
                  continue
              stem = p.stem
              txt = p.read_text(encoding='utf-8', errors='ignore')
              lines = txt.splitlines()
              if lines and lines[0].startswith('\ufeff'):
                  lines[0] = lines[0].lstrip('\ufeff')

              i=0; fm_start=fm_end=-1
              if i < len(lines) and lines[i].strip()=='---':
                  fm_start=i; i+=1
                  while i < len(lines) and lines[i].strip()!='---': i+=1
                  if i < len(lines): fm_end=i; i+=1
              content_start=i

              body = '\n'.join(lines[content_start:])
              body_no_h1 = re.sub(r'^\s*#.*$', '', body, flags=re.M)
              paras = [x.strip() for x in re.split(r'\n\s*\n', body_no_h1) if x.strip()]
              desc=''
              for para in paras:
                  if para.startswith('!'): continue
                  cand = strip_md(para)
                  if len(cand) >= 40:
                      desc = cand; break
              if not desc and paras:
                  desc = strip_md(paras[0])
              if len(desc) > 160:
                  cut = desc[:160]
                  desc = cut[:cut.rfind(' ')] if ' ' in cut else cut

              sample = '\n'.join(lines[content_start:content_start+6])
              tags = list(dict.fromkeys(re.findall(r'(?<!\w)#([a-zA-Z0-9_\-]+)', sample)))

              def upsert_frontmatter(lines, key, val):
                  nonlocal fm_start, fm_end, content_start
                  line = f'{key}: {val}'
                  if fm_start != -1:
                      for k in range(fm_start+1, fm_end):
                          if re.match(rf'^\s*{key}\s*:', lines[k], flags=re.I):
                              lines[k] = line; return lines
                      lines.insert(fm_start+1, line); fm_end += 1; content_start += 1
                      return lines
                  else:
                      lines = ['---', line, '---', ''] + lines
                      fm_start = 0; fm_end = 2; content_start = 4
                      return lines

              lines = upsert_frontmatter(lines, 'title', f'"{stem}"')
              if desc:
                  lines = upsert_frontmatter(lines, 'description', f'"{desc}"')
              if tags:
                  lines = upsert_frontmatter(lines, 'tags', '[' + ', '.join(tags) + ']')

              in_code=False
              fence=re.compile(r'^\s*(`{3,}|~{3,})')
              atx=re.compile(r'^\s{0,3}#{1,6}\s+.*$')
              j=content_start; done=False
              while j < len(lines):
                  if fence.match(lines[j]): in_code = not in_code; j+=1; continue
                  if not in_code and atx.match(lines[j]): lines[j] = '# ' + stem; done=True; break
                  j+=1
              if not done:
                  lines.insert(content_start, '# ' + stem)

              p.write_text('\n'.join(lines) + '\n', encoding='utf-8')
          PY
      - name: Normalize titles (filename -> H1 + front-matter)
        run: |
          python - <<'PY'
          import re, pathlib
          root = pathlib.Path('docs')
          for p in root.rglob('*.md'):
              sp = str(p).replace('\\','/')
              if '/assets/' in sp:
                  continue
              stem = p.stem
              txt = p.read_text(encoding='utf-8', errors='ignore')
              lines = txt.splitlines()
              if lines and lines[0].startswith('\ufeff'):
                  lines[0] = lines[0].lstrip('\ufeff')
              i = 0; fm_start = fm_end = -1
              if i < len(lines) and lines[i].strip() == '---':
                  fm_start = i; i += 1
                  while i < len(lines) and lines[i].strip() != '---':
                      i += 1
                  if i < len(lines) and lines[i].strip() == '---':
                      fm_end = i; i += 1
              content_start = i
              if fm_start != -1:
                  tline = None
                  for k in range(fm_start+1, fm_end):
                      if re.match(r'^\s*title\s*:', lines[k], flags=re.I):
                          tline = k; break
                  title_val = f'title: "{stem}"'
                  if tline is not None:
                      lines[tline] = title_val
                  else:
                      lines.insert(fm_start+1, title_val)
                      fm_end += 1
                      content_start += 1
              else:
                  lines = ['---', f'title: "{stem}"', '---', ''] + lines
                  content_start = 4
              in_code = False
              fence = re.compile(r'^\s*(`{3,}|~{3,})')
              atx = re.compile(r'^\s{0,3}#{1,6}\s+.*$')
              set1 = re.compile(r'^\s*={3,}\s*$')
              set2 = re.compile(r'^\s*-{3,}\s*$')
              j = content_start
              done = False
              while j < len(lines):
                  if fence.match(lines[j]):
                      in_code = not in_code
                      j += 1; continue
                  if not in_code:
                      if atx.match(lines[j]):
                          lines[j] = '# ' + stem
                          done = True
                          break
                      if j+1 < len(lines) and (set1.match(lines[j+1]) or set2.match(lines[j+1])):
                          lines[j] = '# ' + stem
                          del lines[j+1]
                          done = True
                          break
                  j += 1
              if not done:
                  lines.insert(content_start, '# ' + stem)
              p.write_text('\n'.join(lines) + '\n', encoding='utf-8')
          PY
      - run: mkdocs build --site-dir site
      - uses: actions/upload-pages-artifact@v3
        with:
          path: site

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
